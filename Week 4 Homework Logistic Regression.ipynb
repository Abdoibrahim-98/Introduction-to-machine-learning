{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ef8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6720e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Breast_Cancer_Wisconsin_(Diagnostic)_Data_Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714b00ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77be2b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aba0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)\n",
    "df.diagnosis = [1 if each == \"M\" else 0 for each in df.diagnosis]\n",
    "y = df.diagnosis.values\n",
    "x_data = df.drop(['diagnosis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc9b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee550f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABDO\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n",
      "C:\\Users\\ABDO\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "# normalization\n",
    "x = (x_data -np.min(x_data))/(np.max(x_data)-np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8cd70f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                  0.605518  ...      0.620776       0.141525   \n",
       "1                  0.141323  ...      0.606901       0.303571   \n",
       "2                  0.211247  ...      0.556386       0.360075   \n",
       "3                  1.000000  ...      0.248310       0.385928   \n",
       "4                  0.186816  ...      0.519744       0.123934   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                0.132056  ...      0.623266       0.383262   \n",
       "565                0.113100  ...      0.560655       0.699094   \n",
       "566                0.137321  ...      0.393099       0.589019   \n",
       "567                0.425442  ...      0.633582       0.730277   \n",
       "568                0.187026  ...      0.054287       0.489072   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           0.668310    0.450698          0.601136           0.619292   \n",
       "1           0.539818    0.435214          0.347553           0.154563   \n",
       "2           0.508442    0.374508          0.483590           0.385375   \n",
       "3           0.241347    0.094008          0.915472           0.814012   \n",
       "4           0.506948    0.341575          0.437364           0.172415   \n",
       "..               ...         ...               ...                ...   \n",
       "564         0.576174    0.452664          0.461137           0.178527   \n",
       "565         0.520892    0.379915          0.300007           0.159997   \n",
       "566         0.379949    0.230731          0.282177           0.273705   \n",
       "567         0.668310    0.402035          0.619626           0.815758   \n",
       "568         0.043578    0.020497          0.124084           0.036043   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.568610              0.912027        0.598462   \n",
       "1           0.192971              0.639175        0.233590   \n",
       "2           0.359744              0.835052        0.403706   \n",
       "3           0.548642              0.884880        1.000000   \n",
       "4           0.319489              0.558419        0.157500   \n",
       "..               ...                   ...             ...   \n",
       "564         0.328035              0.761512        0.097575   \n",
       "565         0.256789              0.559450        0.198502   \n",
       "566         0.271805              0.487285        0.128721   \n",
       "567         0.749760              0.910653        0.497142   \n",
       "568         0.000000              0.000000        0.257441   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                   0.418864  \n",
       "1                   0.222878  \n",
       "2                   0.213433  \n",
       "3                   0.773711  \n",
       "4                   0.142595  \n",
       "..                       ...  \n",
       "564                 0.105667  \n",
       "565                 0.074315  \n",
       "566                 0.151909  \n",
       "567                 0.452315  \n",
       "568                 0.100682  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68b5d098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (30, 455)\n",
      "x test:  (30, 114)\n",
      "y train:  (455,)\n",
      "y test:  (114,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x train: \",x_train.shape)\n",
    "print(\"x test: \",x_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817a81ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (30, 455)\n",
      "x test:  (30, 114)\n",
      "y train:  (455,)\n",
      "y test:  (114,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x train: \",x_train.shape)\n",
    "print(\"x test: \",x_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b595868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% sigmoid\n",
    "# calculation of z\n",
    "#z = np.dot(w.T,x_train)+b\n",
    "def sigmoid(z):\n",
    "    return  1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9497993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% forward and backward\n",
    "# In backward propagation we will use y_head that found in forward progation\n",
    "# Therefore instead of writing backward propagation method, lets combine forward propagation and backward propagation\n",
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = (-y_train*np.log(y_head))-((1-y_train)*np.log(1-y_head))\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8177c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%# Updating(learning) parameters\n",
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iterarion):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    # we update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d12e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  # prediction\n",
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction\n",
    "# predict(parameters[\"weight\"],parameters[\"bias\"],x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10f2ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w=np.full((dimension,1),0.01)\n",
    "    b=0.0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a88f9522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692977\n",
      "Cost after iteration 10: 0.499667\n",
      "Cost after iteration 20: 0.406616\n",
      "Cost after iteration 30: 0.351936\n",
      "Cost after iteration 40: 0.315762\n",
      "Cost after iteration 50: 0.289862\n",
      "Cost after iteration 60: 0.270257\n",
      "Cost after iteration 70: 0.254795\n",
      "Cost after iteration 80: 0.242214\n",
      "Cost after iteration 90: 0.231722\n",
      "Cost after iteration 100: 0.222796\n",
      "Cost after iteration 110: 0.215080\n",
      "Cost after iteration 120: 0.208317\n",
      "Cost after iteration 130: 0.202324\n",
      "Cost after iteration 140: 0.196961\n",
      "Cost after iteration 150: 0.192121\n",
      "Cost after iteration 160: 0.187722\n",
      "Cost after iteration 170: 0.183698\n",
      "Cost after iteration 180: 0.179997\n",
      "Cost after iteration 190: 0.176577\n",
      "Cost after iteration 200: 0.173402\n",
      "Cost after iteration 210: 0.170443\n",
      "Cost after iteration 220: 0.167676\n",
      "Cost after iteration 230: 0.165080\n",
      "Cost after iteration 240: 0.162638\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.7032967032967 %\n",
      "test accuracy: 96.49122807017544 %\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 4096\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    # do not change learning rate\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate =1 , num_iterations = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "376521a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9824561403508771 \n",
      "train accuracy: 0.967032967032967 \n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(random_state = 42,max_iter= 200, )\n",
    "logreg.fit(x_train.T, y_train.T)\n",
    "print(\"test accuracy: {} \".format(logreg.score(x_test.T, y_test.T)))\n",
    "print(\"train accuracy: {} \".format(logreg.score(x_train.T, y_train.T)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
